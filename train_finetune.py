#!/usr/bin/env python3
"""
Qwenæ¨¡å‹å¾®è°ƒä¸»è®­ç»ƒè„šæœ¬
"""

import os
import argparse
import json
from data_processor import MultiwozDataProcessor
from finetuning_trainer import QwenFineTuner, FineTuningConfig
from evaluator import ModelEvaluator

def main():
    parser = argparse.ArgumentParser(description="Fine-tune Qwen model for human-robot interaction")
    parser.add_argument("--data_dir", type=str, default="data", help="Directory containing training data")
    parser.add_argument("--output_dir", type=str, default="./qwen_finetuned", help="Output directory for the model")
    parser.add_argument("--model_name", type=str, default="Qwen/Qwen2.5-7B-Instruct", 
                       help="Base model name (Qwen2.5 or Qwen3)")
    parser.add_argument("--epochs", type=int, default=3, help="Number of training epochs")
    parser.add_argument("--batch_size", type=int, default=2, help="Training batch size")
    parser.add_argument("--learning_rate", type=float, default=2e-4, help="Learning rate")
    parser.add_argument("--lora_r", type=int, default=16, help="LoRA rank")
    parser.add_argument("--lora_alpha", type=int, default=32, help="LoRA alpha")
    parser.add_argument("--max_length", type=int, default=2048, help="Maximum sequence length")
    parser.add_argument("--skip_preprocessing", action="store_true", help="Skip data preprocessing")
    parser.add_argument("--evaluate_only", action="store_true", help="Only run evaluation")
    parser.add_argument("--use_8bit", action="store_true", help="Use 8-bit quantization instead of 4-bit")
    
    args = parser.parse_args()
    
    # è®¾ç½®wandbç¯å¢ƒå˜é‡ï¼ˆå¦‚æœå·²é…ç½®API keyï¼‰
    if os.getenv("WANDB_API_KEY") and not os.getenv("WANDB_PROJECT"):
        os.environ["WANDB_PROJECT"] = "qwen-finetuning"
        print("ğŸ“Š WandB project set to 'qwen-finetuning'")
    
    print("=" * 60)
    print("ğŸ¤– Qwen Model Fine-tuning for Human-Robot Interaction")
    print("=" * 60)
    print(f"ğŸ“‚ Data directory: {args.data_dir}")
    print(f"ğŸ’¾ Output directory: {args.output_dir}")
    print(f"ğŸ”¥ Base model: {args.model_name}")
    print(f"ğŸ”„ Training epochs: {args.epochs}")
    print(f"ğŸ“¦ Batch size: {args.batch_size}")
    print(f"ğŸ“ˆ Learning rate: {args.learning_rate}")
    print(f"ğŸ¯ LoRA rank: {args.lora_r}")
    print(f"âš¡ LoRA alpha: {args.lora_alpha}")
    print(f"ğŸ“ Max length: {args.max_length}")
    print(f"ğŸ”§ Quantization: {'8-bit' if args.use_8bit else '4-bit'}")
    
    # æ˜¾ç¤ºwandbçŠ¶æ€
    if os.getenv("WANDB_PROJECT"):
        print(f"ğŸ“Š WandB tracking: âœ… (Project: {os.getenv('WANDB_PROJECT')})")
    else:
        print("ğŸ“Š WandB tracking: âŒ (Set WANDB_API_KEY to enable)")
    
    print("=" * 60)
    
    # æ­¥éª¤1: æ•°æ®é¢„å¤„ç†
    if not args.skip_preprocessing and not args.evaluate_only:
        print("\n=== Step 1: Data Preprocessing ===")
        processor = MultiwozDataProcessor(args.data_dir)
        dataset = processor.process_all_data()
        processor.save_processed_data(dataset)
        print("Data preprocessing completed!")
    
    # æ­¥éª¤2: æ¨¡å‹å¾®è°ƒ
    if not args.evaluate_only:
        print("\n=== Step 2: Model Fine-tuning ===")
        
        # é…ç½®å¾®è°ƒå‚æ•°
        config = FineTuningConfig(
            model_name=args.model_name,
            output_dir=args.output_dir,
            num_train_epochs=args.epochs,
            per_device_train_batch_size=args.batch_size,
            learning_rate=args.learning_rate,
            lora_r=args.lora_r,
            lora_alpha=args.lora_alpha,
            max_length=args.max_length,
            use_4bit=not args.use_8bit  # å¦‚æœæŒ‡å®š8bitï¼Œåˆ™ä¸ä½¿ç”¨4bit
        )
        
        # åˆ›å»ºè®­ç»ƒå™¨å¹¶å¼€å§‹è®­ç»ƒ
        trainer = QwenFineTuner(config)
        trainer.train(
            train_data_path="processed_data/train.json",
            eval_data_path="processed_data/validation.json"
        )
        print("Model fine-tuning completed!")
    
    # æ­¥éª¤3: æ¨¡å‹è¯„ä¼°
    if os.path.exists(args.output_dir):
        print("\n=== Step 3: Model Evaluation ===")
        
        # ä½¿ç”¨ä¸“é—¨çš„è¯„ä¼°å™¨
        evaluator = ModelEvaluator(args.output_dir, base_model_name=args.model_name)
        
        # ç®€å•æµ‹è¯•ç”Ÿæˆ
        print("\n=== Quick Generation Test ===")
        test_prompts = [
            "Can you help me assemble a phone?",
            "I need to deliver a package to the warehouse.",
            "Where can I find the laser cell?",
            "Bring me the red fuse from the electrical box."
        ]
        
        for prompt in test_prompts:
            print(f"\nUser: {prompt}")
            # æ„å»ºå®Œæ•´çš„prompt
            full_prompt = f"<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n"
            response = evaluator.generate_response(full_prompt)
            print(f"Assistant: {response}")
    
    else:
        print(f"Model directory {args.output_dir} not found. Please train the model first.")
    
    print("\n=== Fine-tuning Pipeline Completed ===")

if __name__ == "__main__":
    main()
